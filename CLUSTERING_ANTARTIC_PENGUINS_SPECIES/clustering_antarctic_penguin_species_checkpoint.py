# -*- coding: utf-8 -*-
"""Clustering Antarctic Penguin Species-checkpoint.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gDvqgeRfpPTPQs2bouc28fVhJ5MgHvTD

#Arctic Penguin Exploration: Unraveling Clusters in the Icy Domain with K-means clustering

**Origin of this data :** Data were collected and made available by Dr. Kristen Gorman and the Palmer Station, Antarctica LTER, a member of the Long Term Ecological Research Network.

###The dataset consists of 5 columns.



1. culmen_length_mm: culmen length (mm)
2. culmen_depth_mm: culmen depth (mm)
3. flipper_length_mm: flipper length (mm)
4. body_mass_g: body mass (g)
5. sex: penguin sex

Unfortunately, they have not been able to record the species of penguin, but they know that there are three species that are native to the region: ***Adelie, Chinstrap***, and **Gentoo,** so your task is to apply your data science skills to help them identify groups in the dataset!
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

"""#Loading and examining the dataset"""

penguins_df = pd.read_csv('/content/penguins.csv')
penguins_df.head()

penguins_df.shape

penguins_df.info()

"""#Dealing with null values and outliers"""

penguins_df.isna().sum()

penguins_df.dropna(inplace=True)
penguins_df

penguins_df.isna().sum()

penguins_df.describe()

penguins_df.boxplot()

penguins_clean = penguins_df[(penguins_df['flipper_length_mm'] < 3000) & (penguins_df ['flipper_length_mm'] > 0)]

penguins_clean.describe()

penguins_clean.boxplot()

"""#Perform preprocessing steps on the dataset to create dummy variables"""

penguins_clean = pd.get_dummies(penguins_clean, drop_first = True)

"""#Perform preprocessing steps on the dataset - scaling"""

scaler = StandardScaler()
penguins_prepocessed = scaler.fit_transform(penguins_clean)

"""#Perform PCA"""

pca = PCA(n_components=None)
pca.fit(penguins_prepocessed)
n_components = sum(pca.explained_variance_ratio_>0.1)

pca = PCA(n_components=n_components)
penguins_PCA = pca.fit_transform(penguins_prepocessed)

"""#Detect the optimal number of clusters for k-means clustering"""

inertia = []

for k in range(1,10):
  kmeans = KMeans(n_clusters=k , random_state=42).fit(penguins_PCA)
  inertia.append(kmeans.inertia_)

plt.plot(range(1,10), inertia, marker='o')
plt.xlabel('Number of clusters')
plt.ylabel('Inertia')
plt.title('Elbow method')
plt.show()
n_clusters=4

"""#Run the k-means clustering algorithm
  
"""

kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(penguins_PCA)

plt.scatter(penguins_PCA[:, 0], penguins_PCA[:, 1], c=kmeans.labels_)
plt.xlabel('First Principal Component')
plt.ylabel('Second Principal Component')
plt.title(f'K-means Clustering (K={n_clusters})')
plt.legend()
plt.show()

"""#Create a final statistical DataFrame for each cluster."""

penguins_clean['label'] = kmeans.labels_

numeric_columns = ['culmen_length_mm', 'culmen_depth_mm' , 'flipper_length_mm', 'label']

stat_penguins = penguins_clean.groupby('label')[numeric_columns].mean()

stat_penguins